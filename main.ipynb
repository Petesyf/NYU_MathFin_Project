{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from communities.algorithms import louvain_method\n",
    "import time\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import threading\n",
    "\n",
    "# get correlation matrix file names\n",
    "data_folder = \"Data/Corr_Mat\"\n",
    "output_folder = \"Data/Ticker_List\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def download_stock_pool_data():\n",
    "    # get data directory path\n",
    "    cur_path = os.path.dirname(__file__)\n",
    "    data_directory_path = os.path.relpath('../Data', cur_path)\n",
    "\n",
    "    # get latest russell 1000 constituents\n",
    "    russell1000_info = pd.read_excel(io=data_directory_path + \"\\\\Russell_1000_Constituents_20221007.xlsx\",\n",
    "                                     sheet_name=\"Holdings\", skiprows=range(7))\n",
    "    # get list of tickers\n",
    "    stocks_pool_list = list(russell1000_info.Ticker.values)\n",
    "    # get historical market data of current Russel 1000 constituents\n",
    "    stocks_pool_data = yf.Tickers(stocks_pool_list).history(start=\"2012-01-01\")[\"Close\"]\n",
    "\n",
    "    # get historical market data of S&P500\n",
    "    sp500_data = pd.DataFrame(yf.Ticker(\"^GSPC\").history(start=\"2012-01-01\")[\"Close\"])\n",
    "    # rename S&P 500 data column\n",
    "    sp500_data.columns = [\"SP500\"]\n",
    "\n",
    "    # merge two dataframes\n",
    "    raw_data = stocks_pool_data.join(sp500_data)\n",
    "\n",
    "    # drop stocks with more than 1000 NaNs\n",
    "    raw_data = raw_data.dropna(axis=\"columns\", thresh=2500)\n",
    "\n",
    "    # save stock pool data into csv\n",
    "    raw_data.to_csv(data_directory_path + \"\\\\Raw_Data_20221007.csv\")\n",
    "\n",
    "# # get stock pool data from yahoo finance\n",
    "# download_stock_pool_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Correlation Matrices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def generate_residual_matrices():\n",
    "    # get data directory path\n",
    "    cur_path = os.path.dirname(__file__)\n",
    "    data_directory_path = os.path.relpath('../Data', cur_path)\n",
    "    # read data from file\n",
    "    raw_data = pd.read_csv(data_directory_path + \"\\\\Raw_Data_20221007.csv\", index_col=0)\n",
    "\n",
    "    # set rebalancing frequency: every month\n",
    "    rebalance_freq_period = relativedelta(months=1)\n",
    "    # set business day convention for rebalancing\n",
    "    business_day_convention = \"Modified Following\"\n",
    "    # training set length\n",
    "    train_set_length_period = relativedelta(months=6)\n",
    "    # set date range\n",
    "    first_date = datetime.strptime(raw_data.index[0], \"%Y-%m-%d\")\n",
    "    last_date = datetime.strptime(raw_data.index[-1], \"%Y-%m-%d\")\n",
    "\n",
    "    # initialize date range\n",
    "    train_start_date = first_date\n",
    "    train_end_date = train_start_date + train_set_length_period - relativedelta(days=1)\n",
    "\n",
    "    test_start_date = train_end_date + relativedelta(days=1)\n",
    "    test_end_date = test_start_date + rebalance_freq_period\n",
    "\n",
    "    # traverse the data set\n",
    "    while test_end_date < last_date:\n",
    "        # do regression\n",
    "        temp_train_data = raw_data.loc[train_start_date.__str__()[:10]:test_start_date.__str__()[:10], :]\n",
    "        # save the residuals\n",
    "        temp_residuals = pd.DataFrame(index=temp_train_data.index, columns=temp_train_data.columns.drop(\"SP500\"))\n",
    "        for ticker in temp_residuals.columns:\n",
    "            # get data\n",
    "            y_x = temp_train_data[[ticker, \"SP500\"]]\n",
    "            # drop nas\n",
    "            y_x = y_x.dropna(axis=\"index\", how=\"any\")\n",
    "            # rename columns\n",
    "            y_x.columns = [\"y\", \"x\"]\n",
    "            # whether there's sufficient trading days\n",
    "            if len(y_x.index) < len(temp_train_data) * 0.9:\n",
    "                continue\n",
    "            else:\n",
    "                # calculate returns\n",
    "                y_x = np.log(y_x).diff().dropna(axis=\"index\", how=\"any\")\n",
    "                y = np.array(y_x[\"y\"])\n",
    "                x = np.array(y_x[\"x\"]).reshape(-1, 1)\n",
    "                # do regression\n",
    "                reg = LinearRegression(fit_intercept=True).fit(x, y)\n",
    "                # calculate residual\n",
    "                y_x.loc[:, \"res\"] = np.subtract(y, (reg.intercept_ - reg.coef_[0] * x)[:, 0])\n",
    "                # add residual to temp_residuals\n",
    "                temp_residuals.loc[y_x.index, ticker] = y_x.res\n",
    "        # drop nans in dataframe\n",
    "        temp_residuals = temp_residuals.dropna(axis=\"index\", how=\"all\")\n",
    "        temp_residuals = temp_residuals.dropna(axis=\"columns\", how=\"any\")\n",
    "        # calculate correlations\n",
    "        temp_residuals = temp_residuals.astype(float)\n",
    "        temp_corr_matrix = temp_residuals.corr()\n",
    "\n",
    "        # save the matrix to file\n",
    "        temp_corr_matrix.to_csv(data_directory_path + \"\\\\Corr_Mat\\\\\" + train_start_date.__str__()[:10] + \".csv\")\n",
    "\n",
    "        # update dates\n",
    "        train_start_date += rebalance_freq_period\n",
    "        test_start_date += rebalance_freq_period\n",
    "        test_end_date += rebalance_freq_period\n",
    "\n",
    "# # calculate correlation between residuals of stocks during 6M period\n",
    "# generate_residual_matrices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Graph Into Communities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_communities(file_name:str, input_folder:str = data_folder):\n",
    "    print(file_name)\n",
    "    # get correlation matrix\n",
    "    corr_mat = pd.read_csv(input_folder+\"/\"+file_name, index_col=0)\n",
    "    # convert to adjacency matrix\n",
    "    adj_mat = np.abs(corr_mat - np.diag(np.diag(corr_mat)))\n",
    "    # using Louvain method to split the graph into 20 communities\n",
    "    communities, _ = louvain_method(adj_mat.values, 20)\n",
    "    # get ticker list of each community\n",
    "    cluster_list = []\n",
    "    for community in communities:\n",
    "        cluster = list(community)\n",
    "        cluster_list.append(adj_mat.columns[cluster])\n",
    "    # save the list to txt\n",
    "    global output_folder\n",
    "    with open(output_folder + \"/\"+file_name.replace(\".csv\",\".txt\"), 'w') as f:\n",
    "        for cluster in cluster_list:\n",
    "            f.write(str(list(cluster)) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MyThread(threading.Thread):\n",
    "\n",
    "    def __init__(self, func, arg):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.arg = arg\n",
    "\n",
    "    def run(self):\n",
    "        self.func(*self.arg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 start, current time = 2022-10-14 03:25:55.570050\n",
      "2013-12-03.csv\n",
      "2014-01-03.csv\n",
      "2014-02-03.csv\n",
      "2014-03-03.csv\n",
      "2014-04-03.csv\n",
      "2014-05-03.csv\n",
      "2014-06-03.csv\n",
      "2014-07-03.csv\n",
      "Iteration 2 start, current time = 2022-10-14 05:34:21.051339\n",
      "2014-08-03.csv2014-09-03.csv\n",
      "\n",
      "2014-10-03.csv\n",
      "2014-11-03.csv\n",
      "2014-12-03.csv\n",
      "2015-01-03.csv\n",
      "2015-02-03.csv\n",
      "2015-03-03.csv\n",
      "Iteration 3 start, current time = 2022-10-14 07:44:36.677298\n",
      "2015-04-03.csv\n",
      "2015-05-03.csv\n",
      "2015-06-03.csv\n",
      "2015-07-03.csv\n",
      "2015-08-03.csv\n",
      "2015-09-03.csv\n",
      "2015-10-03.csv\n",
      "2015-11-03.csv\n",
      "Iteration 4 start, current time = 2022-10-14 10:00:09.037116\n",
      "2015-12-03.csv\n",
      "2016-01-03.csv\n",
      "2016-02-03.csv2016-03-03.csv\n",
      "\n",
      "2016-04-03.csv\n",
      "2016-05-03.csv2016-06-03.csv\n",
      "\n",
      "2016-07-03.csv\n",
      "Iteration 5 start, current time = 2022-10-14 12:44:14.068682\n",
      "2016-08-03.csv\n",
      "2016-09-03.csv\n",
      "2016-10-03.csv\n",
      "2016-11-03.csv\n",
      "2016-12-03.csv\n",
      "2017-01-03.csv\n",
      "2017-02-03.csv\n",
      "2017-03-03.csv\n",
      "Iteration 6 start, current time = 2022-10-14 15:33:07.077394\n",
      "2017-04-03.csv\n",
      "2017-05-03.csv\n",
      "2017-06-03.csv\n",
      "2017-07-03.csv\n",
      "2017-08-03.csv\n",
      "2017-09-03.csv\n",
      "2017-10-03.csv\n",
      "2017-11-03.csv\n",
      "Iteration 7 start, current time = 2022-10-14 17:48:11.672953\n",
      "2017-12-03.csv\n",
      "2018-01-03.csv\n",
      "2018-02-03.csv\n",
      "2018-03-03.csv\n",
      "2018-04-03.csv\n",
      "2018-05-03.csv\n",
      "2018-06-03.csv\n",
      "2018-07-03.csv\n",
      "Iteration 8 start, current time = 2022-10-14 20:11:52.449764\n",
      "2018-08-03.csv\n",
      "2018-09-03.csv\n",
      "2018-10-03.csv\n",
      "2018-11-03.csv\n",
      "2018-12-03.csv\n",
      "2019-01-03.csv2019-02-03.csv\n",
      "2019-03-03.csv\n",
      "\n",
      "Iteration 9 start, current time = 2022-10-14 23:03:42.409186\n",
      "2019-04-03.csv\n",
      "2019-05-03.csv\n",
      "2019-06-03.csv\n",
      "2019-07-03.csv\n",
      "2019-08-03.csv\n",
      "2019-09-03.csv\n",
      "2019-10-03.csv2019-11-03.csv\n",
      "\n",
      "Iteration 10 start, current time = 2022-10-15 02:19:33.979451\n",
      "2019-12-03.csv\n",
      "2020-01-03.csv\n",
      "2020-02-03.csv\n",
      "2020-03-03.csv\n",
      "2020-04-03.csv\n",
      "2020-05-03.csv\n",
      "2020-06-03.csv2020-07-03.csv\n",
      "\n",
      "Iteration 11 start, current time = 2022-10-15 05:36:12.481885\n",
      "2020-08-03.csv\n",
      "2020-09-03.csv\n",
      "2020-10-03.csv\n",
      "2020-11-03.csv\n",
      "2020-12-03.csv\n",
      "2021-01-03.csv2021-02-03.csv\n",
      "\n",
      "2021-03-03.csv\n",
      "Iteration 12 start, current time = 2022-10-15 08:35:45.762202\n",
      "2021-04-03.csv\n",
      "2021-05-03.csv\n",
      "2021-06-03.csv\n",
      "2021-07-03.csv2021-08-03.csv\n",
      "\n",
      "2021-09-03.csv\n",
      "2021-10-03.csv2021-11-03.csv\n",
      "\n",
      "Iteration 13 start, current time = 2022-10-15 11:15:26.132928\n",
      "2021-12-03.csv\n",
      "2022-01-03.csv\n",
      "2022-02-03.csv\n",
      "2022-03-03.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_24336/1449268569.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0mfile_name_list\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;31m# file_name_list = os.listdir(data_folder)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m \u001B[0mget_all_communities\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_name_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_folder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_24336/1449268569.py\u001B[0m in \u001B[0;36mget_all_communities\u001B[1;34m(file_list, input_folder, thread_num)\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Iteration {} start, current time = {}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m//\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_num\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m             \u001B[0mfile_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfile_list\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m             \u001B[0mthread\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMyThread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_communities\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_folder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m             \u001B[0mthread\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_all_communities(file_list:list[str] = os.listdir(data_folder), input_folder:str = data_folder, thread_num:int = 8):\n",
    "    # create 8 threads\n",
    "    for i in range(0, len(file_list), thread_num):\n",
    "        thread_list = []\n",
    "        print(\"Iteration {} start, current time = {}\".format(i//8+1, datetime.now()))\n",
    "        for j in range(thread_num):\n",
    "            file_name = file_list[i + j]\n",
    "            thread = MyThread(get_communities, (file_name, input_folder))\n",
    "            thread.start()\n",
    "            thread_list.append(thread)\n",
    "        for thread in thread_list:\n",
    "            thread.join()\n",
    "\n",
    "# generate clusters of tickers and save them to txt file\n",
    "file_name_list = []\n",
    "for file in os.listdir(data_folder):\n",
    "    if file > \"2013-11-03.csv\":\n",
    "        file_name_list.append(file)\n",
    "\n",
    "# file_name_list = os.listdir(data_folder)\n",
    "get_all_communities(file_name_list, data_folder, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Centroids of Clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
